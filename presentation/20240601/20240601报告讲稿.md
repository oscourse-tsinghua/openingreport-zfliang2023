---
theme: 共享调度器 + 中断控制器报告
time: 2024.06.01
---

# 操作系统中的异步与任务调度机制研究

---------------------------------

大家好，今天我汇报的题目是操作系统中的异步与任务调度机制研究，指导老师是向勇老师。

---------------------------------

现代数据中心要求操作系统必须具备高效资源利用、快速响应以及适应高并发等特征，这些要求凸显了异步机制在操作系统设计中的重要性。

但提到异步就不得不提任务调度，异步机制允许在等待某些操作完成时，CPU可以被其他任务使用，这与任务调度机制的目标一致，即最大化CPU资源的利用。这两者密切相关，共同确保了操作系统的高效和响应性。

在操作系统中，无论是内核还是用户程序，都需要异步机制和任务调度机制来保证与外界进行高效的交互。就任务调度而言，在内核和用户程序中，已经存在很多成熟的调度算法以及库；而内核与用户程序中的异步支持则不同：

1. 内核中的异步支持主要由中断机制提供；
2. 而用户态的异步支持则主要是通过内核提供的系统调用机制提供，近年来，在 x86 以及 RISC-V 平台上，出现了用户态中断机制，增强了用户态的异步支持。

---------------------------------

尽管目前的操作系统提供了异步机制且具有成熟的任务调度机制，但还存在着以下问题：

1. 首先，内核无法感知到用户态的任务，从而导致无法更细粒度的控制用户态任务调度。以1对多线程模型为例，但某个用户线程阻塞时，其他的用户线程都将无法执行。
2. 其次，内核中对异步机制的支持通常需要在线程调度的基础上，增加额外的运行时，增加了内核的复杂性。例如 linux 中的 epoll 异步机制强制使用生产者消费者模型进行事件分发，除了 socket 和进程之外，还需要操作 eventpoll 对象。
3. 此外，中断、系统调用这些机制本身的开销不可忽略。左图描述了由于系统调用导致的性能开销，其中 IPC 标识每个周期执行的指令数（Instruction per cycle）。右图统计了由于中断导致的直接开销。

---------------------------------

针对上述现状与问题，我们旨在构建一个异步操作系统，尝试打通从内核、用户程序与外界的异步交互通道。

首先针对用户程序到内核之间的交互，我们构建了 COPS 运行时，改造了异步系统调用，增强了用户态的异步支持。

其次，针对内核与外界之间的交互，我们使用 TAIC 中断控制器实现了开销更小的异步机制。

---------------------------------

首先，介绍一下 COPS 异步运行时环境。我们的目标是：

让内核能够感知用户态的任务；
统一内核与用户态的任务调度；
增强用户态的异步支持；

为了达成以上目标，

我们首先在内核中引入了协程，使用协程来替代传统的多线程并发模型，让协程成为内核、用户进程的最小任务单元。
在此基础上，我们通过 vDSO 机制构建了一套在内核与用户进程中共享的运行时环境——COPS，从而统一了内核与用户态的任务调度，减小了内核调度的复杂性，并且共享运行时，能够避免内存资源浪费。
COPS 使用基于协程的任务控制块，通过维护任务控制块中的优先级字段以及局部优先级位图，使得内核与用户进程在各自的地址空间内能够实现优先级调度。

并且 COPS 在内核中维护了全局优先级位图，在产生时钟中断时，内核更新全局位图，而用户进程只拥有对全局位图的可读权限，通过这种方式，COPS 让内核能够感知到用户态的任务。

---------------------------------

此外，COPS 还利用用户态中断机制优化了系统调用，为用户程序提供了更丰富的异步支持。

我们以异步从 socket 中读取数据为例，假设此时 socket 中没有数据。

首先，在 CPU0 上运行的用户进程的协程A，执行异步读系统调用，进入内核注册内核系统调用处理协程后，马上返回用户态；
用户态的协程进入阻塞状态，执行其他协程
当在 CPU1 上运行的内核收到网卡产生的中断后，唤醒了内核对应系统调用处理协程；
内核协程执行完毕后，使用用户态中断唤醒在 CPU0 上运行的进程的阻塞协程。

---------------------------------

我们在 FPGA 上对 COPS 进行了测试，我们 FPGA 中的 riscv 子系统中构建了一个服务端，服务端由接收请求模块、处理模块和返回响应模块组成，PC 上的客户端向服务端发送请求。
首先，我们对比了分别使用线程、协程来实现服务端三个模块的内存占用，由于线程需要分配固定大小的栈，而协程则是按需使用堆内存，因此线程模型的内存占用比协程高（数量级）。
其次，我们通过测量客户端发出请求到接收到服务端响应之间的时延和吞吐量进行了综合测试，证明了 COPS 能够适应高负载的场景。
根据分别在内核与用户态使用线程还是协程，有 4 种组合模型：
KCUC：内核、用户进程均使用协程
KCUT：内核使用协程、用户态使用线程
KTUT：内核与用户态均使用线程
KTUC：内核使用专门线程、用户态使用协程，这与 io_uring 的做法类似
从数据的对比可以看出，COPS 中使用的 KCUC 模型，在负载较小时，不如其他三种模型，但随着负载逐渐增加（连接数>=16时），其优势逐渐明显。在连接数 >=96 时，KCUC 模型的吞吐量已经高于 KTUC 模型。

---------------------------------

COPS 把协程引入内核，让内核能够感知用户态的协程，给内核与用户程序提供了共享的统一的调度，并使用用户态中断机制给用户程序提供异步机制，构建了适用于内核以及上层应用的异步环境。但它没有涉及底层的异步机制支持。因此，我们还设计了TAIC中断控制器。

TAIC的设计目标是减小中断机制的开销，为内核和用户程序提供开销更小的异步支持。其核心思路是让控制器感知任务，从而让控制器能够帮助 CPU 处理中断。

为什么要让控制器感知任务呢？

我们认为CPU 与外设之间的交互存在着信息差。中断机制只包含了 I/O 请求完成的时间，而不包含与 I/O 请求相关联的任务信息；轮询机制虽然包含了与 I/O 请求关联的任务信息，却没有 I/O 请求何时完成的信息。让控制器感知任务，既能够拥有 I/O 请求完成的时间信息，也拥有与 I/O 请求相关联的任务信息，从而弥补了 CPU 与外设之间交互的信息差。

那我们是如何做到让控制器感知任务呢？

我们设计了软硬件协作管理的任务状态模型，其中虚线框内的任务状态由控制器进行维护。
1. 首先是在控制器中维护了就绪队列，让控制器能够感知就绪的任务。
2. 其次，我们将处于阻塞状态的任务进一步被细分为两类：
   1. 一类是由于任务与其他任务存在依赖关系而进入 S-Blocked 状态，这类任务存储在软件管理的阻塞队列中，等待其他任务进行唤醒；
   2. 另一类是因等待 I/O 操作或其他事件而进入 H-Blocked 状态，这类任务由控制器内部的阻塞队列中进行维护。

---------------------------------

我们在这些队列中维护了任务的标识符，当任务 A 的标识符在控制器中的就绪队列时，则控制器能够感知到任务 A 已经准备好执行了；而针对等待 I/O 的任务，我们根据外设的中断源的数量维护数量相等的阻塞队列，分别跟踪因等待不同 I/O 请求而阻塞的标识符。例如，如果网卡接收通道的中断号为 1，而任务 B 因等待网卡接收到的数据包而处于阻塞状态，那么任务 B 的标识符就会被记录在阻塞队列 1 中。通过这种方法，TAIC能够清晰地识别出每个任务因何原因而阻塞。

那么控制器怎么处理中断，唤醒任务呢？我们将中断控制器处理中断的过程称之为快速唤醒。
1. 与传统的中断控制器相似，在初始化时，软件需要写控制器端口，将中断屏蔽位清空，使能快速唤醒机制，但 TAIC 还需要向对应的阻塞队列中注册阻塞任务。（这两项操作是合并的）
2. 传统的中断控制器在接收到设备的中断信号后，只能将中断信号传递给 CPU。而 TAIC 的处理则是在收到中断信号后，将阻塞任务标识符从阻塞队列迁移至就绪队列，完成唤醒操作，并将中断屏蔽位置位，快速唤醒机制失效。
3. 真正的处理任务则与传统的中断控制器不同，需要 CPU 主动从控制器的就绪队列中取出优先级最高的任务执行。（我们将等待的任务设置成较高的优先级，来保证它能够被及时执行）
这样的做法，减少了由于中断带来的直接开销和间接开销，也不需要 CPU 轮询设备状态寄存器，能够继承两种机制的优点。

---------------------------------

我们同样也在 FPGA 上对 TAIC 进行了评估。

首先，我们对比了协程切换的开销以及中断导致的上下文切换开销，协程切换开销低于中断上下文切换开销。
其次，我们分别采用了轮询、中断、TAIC三种机制测量发送一个以太网帧所需要的时钟周期开销。（发送以太网帧需要向网卡提交缓冲区，等待网卡发送完成后回收缓冲区）
轮询机制则是 CPU 不断查询网卡的状态寄存器
中断机制则需要进入中断处理函数中清除状态寄存器再回收
TAIC 则不需要轮询，当设备产生中断后，TAIC 唤醒回收协程，在回收协程中回收缓冲区。根据结果来看，TAIC 将中断的上下文开销减少成了协程切换开销。
随后，我们在系统中增加了额外的矩阵运算，用来模拟 CPU 的其他负载，通过测量客户端发出请求、服务端计算矩阵乘法、服务端发送响应、客户端接收响应之间的时延来间接衡量了三种模式对 CPU 占用率的影响。
Poll 模式的 CPU 占用率最高，中断模式的占用率其次，而 TAIC 模式占用率最小。

---------------------------------

我们还测量了当计算负载与连接相关时，三种模式的时延：

当负载较小时，TAIC 的平均时延与轮询机制相当，但时延小于中断机制；

当连接数增加后，TAIC 的优势逐渐明显，从平均时延以及时延分布可以看出来这个趋势。

---------------------------------

除了进行了上述的微基准测试，我们还进行了综合测试。

我们分别使用了 TAIC 快速唤醒机制、轮询机制构建了不同的网卡驱动，并在 FPGA 中的 riscv 子系统中运行 Arceos-redis 服务端。

我们首先在 PC 上使用了 redis-benchmark 测试了两者在不同的测试场景下的吞吐量。

1. 在所有测试场景下，使用 TAIC 快速唤醒机制的 Redis 每秒能处理的请求数与使用轮询机制的基准相当，在某些测试场景下有所提高。
2. 针对只有 O(1) 时间复杂度的测试，TAIC 快速唤醒机制对 Redis 的吞吐量优化有限。对于操作的时间复杂度大于O(1)或存在其他负载时（例如HSET、SADD、ZADD、SPOP、ZPOP等），吞吐量优化明显。

其次，我们还使用了 YCSB 测试了在不同的负载场景下的吞吐量。

YCSB-A：由50%的读操作和50%的更新操作组成。
YCSB-B：以读操作为主，读操作占95%，写操作占5%。
YCSB-C：只包含读操作，100%的读取。
YCSB-D：在这个工作负载中，新的记录被插入，而最近的插入记录是最热的，即最受频繁访问的。
YCSB-F：客户端将读取一条记录，修改它，然后再次写回。

我们可以得出以下结论：

根据 YCSB-A 以及 YCSB-F 对比结果，TAIC快速唤醒机制在修改频繁的工作场景中，优化较明显，存在6%～7%的提升；
根据 YCSB-B、YCSB-C 和 YCSB-D，TAIC快速唤醒机制在读操作较多的工作场景中优化有限，仅有1%～2%的提升。

---------------------------------

未来，我们计划设计一款能够支持在多个设备、多个 OS、多个进程、多个任务之间进行通信的中断控制器——MOIC，用来提供开销更小的异步通信机制。

其中的关键思路仍是让控制器感知任务，但我们在 TAIC 的基础上建立了完备的任务标识系统。完整的任务标识由 OS 标识、进程标识和任务标识组成。每一级标识由各级控制块的基址、优先级、抢占标记以及下一级标识表的基址组成。

---------------------------------

通过完备的标识系统，MOIC 可以支持

设备与任务之间的通信；
在不同核上运行的相同 OS 内的不同进程内的任务之间通信；
在不同核上运行的不同 OS 内的不同进程内的任务之间通信；

---------------------------------

感谢各位老师和同学聆听！
